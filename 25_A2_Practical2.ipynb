{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb70be6f-b0a4-4c55-9749-0ee607e23a1e",
   "metadata": {},
   "source": [
    "## Name - Anant Jejani\n",
    "## Roll no - 25\n",
    "## Batch - A2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df89dde8-6494-4251-ad57-053f02350fc5",
   "metadata": {},
   "source": [
    "## 1B. Implementation Perceptron Learning algorithm for classification of following points {P0(-1,-1,-1), P1(-1,-1,1), P2(-1,1,-1), P3(-1,1,1),P4(1,-1,-1), P5(1,-1,1), P6(1,1,-1), P7(1,1,1)} into two classes:\n",
    "## C1 = {P7 (1,1,1)}\n",
    "\n",
    "## C2={PO(-1,-1,-1), P1(-1,-1,1), P2(-1,1,-1), P3(-1,1,1), 4(1,-1,-1), P5(1,-1,1), P6(1,1,-1)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7b4dcd-2731-4ad7-801d-3074190f6181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [-1 -1 -1], Predicted: 0, Actual: 0\n",
      "Input: [-1 -1  1], Predicted: 0, Actual: 0\n",
      "Input: [-1  1 -1], Predicted: 0, Actual: 0\n",
      "Input: [-1  1  1], Predicted: 0, Actual: 0\n",
      "Input: [ 1 -1 -1], Predicted: 0, Actual: 0\n",
      "Input: [ 1 -1  1], Predicted: 0, Actual: 0\n",
      "Input: [ 1  1 -1], Predicted: 0, Actual: 0\n",
      "Input: [1 1 1], Predicted: 1, Actual: 1\n",
      "Final Weights: [0.1 0.1 0.1]\n",
      "Final Bias: -0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def perceptron_learning_algorithm(data, targets, learning_rate=0.1, epochs=100):\n",
    "    \n",
    "\n",
    "    n_samples, n_features = data.shape\n",
    "    weights = np.zeros(n_features)\n",
    "    bias = 0\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        for i in range(n_samples):\n",
    "            linear_output = np.dot(data[i], weights) + bias\n",
    "            predicted_output = 1 if linear_output >= 0 else 0\n",
    "\n",
    "            update = learning_rate * (targets[i] - predicted_output)\n",
    "            weights += update * data[i]\n",
    "            bias += update\n",
    "\n",
    "    return weights, bias\n",
    "\n",
    "# Input data and targets\n",
    "data = np.array([[-1, -1, -1], [-1, -1, 1], [-1, 1, -1], [-1, 1, 1], [1, -1, -1], [1, -1, 1], [1, 1, -1], [1, 1, 1]])\n",
    "targets = np.array([0, 0, 0, 0, 0, 0, 0, 1]) # C2 = 0, C1 = 1\n",
    "\n",
    "\n",
    "# Train the perceptron\n",
    "weights, bias = perceptron_learning_algorithm(data, targets)\n",
    "\n",
    "# Test the perceptron\n",
    "for i in range(len(data)):\n",
    "    linear_output = np.dot(data[i], weights) + bias\n",
    "    predicted_output = 1 if linear_output >= 0 else 0\n",
    "    print(f\"Input: {data[i]}, Predicted: {predicted_output}, Actual: {targets[i]}\")\n",
    "\n",
    "print(f\"Final Weights: {weights}\")\n",
    "print(f\"Final Bias: {bias}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c74b9cb-9f32-4e06-82de-160b152cc48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_points = {\n",
    "    'P0': np.array([-1 , -1 , -1]),\n",
    "    'P1': np.array([-1 , -1 , 1]),\n",
    "    'P2': np.array([-1 , 1 , -1]),\n",
    "    'P3': np.array([-1 , 1 , 1]),\n",
    "    'P4': np.array([1 , -1 , -1]),\n",
    "    'P5': np.array([1 , -1 , 1]),\n",
    "    'P6': np.array([1 , 1 , -1]),\n",
    "    'P7': np.array([1 , 1 , 1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc61db81-ecce-46ce-9c8b-1ac94c64ac61",
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = ['P7']\n",
    "C2 = ['P0' , 'P1' , 'P2' , 'P3' , 'P4' , 'P5' , 'P6' ]\n",
    "weights = np.zeros(len(data_points['P0']))\n",
    "bias = 0\n",
    "learning_rate= 0.1\n",
    "epochs = 100\n",
    "for each in range(epochs):\n",
    "    for point in C2:\n",
    "        x= data_points[point]\n",
    "        y= 1\n",
    "        summation = np.dot(weights, x) + bias \n",
    "        if summation<=0:\n",
    "            weights += learning_rate * x\n",
    "            bias += learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc8fb318-cd4c-428a-8a61-8203a400f753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight: [-0.1 -0.1 -0.1] Bias: 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "print(\"weight:\" , weights , \"Bias:\" , bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a309970c-d7f5-4604-856b-5f7de69689bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point = np.array([1,1,1])\n",
    "summation = np.dot(weights , new_point) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ab09ea0-6cdf-40c2-842b-cf55c9528796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new point [1 1 1] belongs to class C1\n"
     ]
    }
   ],
   "source": [
    "if summation > 0:\n",
    "    print(f\"The new point {new_point} belongs to class C2\")\n",
    "else:\n",
    "    print(f\"The new point {new_point} belongs to class C1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b30f563-5170-43e4-83e0-d850e5f27426",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_point = np.array([-1,-1,-1])\n",
    "summation = np.dot(weights , new_point) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "553402f4-5b1a-4cf9-af74-dac3bd878a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "  Misclassified point [-1 -1 -1] - updating weights and bias\n",
      "  Misclassified point [-1  1  1] - updating weights and bias\n",
      "  Misclassified point [ 1 -1  1] - updating weights and bias\n",
      "Epoch 2\n",
      "  Misclassified point [-1 -1  1] - updating weights and bias\n",
      "  Misclassified point [ 1  1 -1] - updating weights and bias\n",
      "Epoch 3\n",
      "  Misclassified point [-1 -1  1] - updating weights and bias\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "\n",
      "Final weights: [0.2 0.2 0.2]\n",
      "Final bias: -0.2\n",
      "Point [-1 -1 -1] predicted as class -1.0 (actual class -1)\n",
      "Point [-1 -1  1] predicted as class -1.0 (actual class -1)\n",
      "Point [-1  1 -1] predicted as class -1.0 (actual class -1)\n",
      "Point [-1  1  1] predicted as class 1.0 (actual class 1)\n",
      "Point [ 1 -1 -1] predicted as class -1.0 (actual class -1)\n",
      "Point [ 1 -1  1] predicted as class 1.0 (actual class 1)\n",
      "Point [ 1  1 -1] predicted as class -1.0 (actual class -1)\n",
      "Point [1 1 1] predicted as class 1.0 (actual class 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the dataset (X) and corresponding labels (y)\n",
    "X = np.array([[-1, -1, -1], [-1, -1, 1], [-1, 1, -1], [-1, 1, 1],\n",
    "              [1, -1, -1], [1, -1, 1], [1, 1, -1], [1, 1, 1]])\n",
    "\n",
    "y = np.array([-1, -1, -1, 1, -1, 1, -1, 1])  # Assigning labels to the points\n",
    "\n",
    "# Perceptron Learning Algorithm\n",
    "def perceptron(X, y, learning_rate=0.1, epochs=10):\n",
    "    # Initialize weights and bias to zero\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    bias = 0\n",
    "    \n",
    "    # Iterate through the data for the given number of epochs\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Epoch {epoch + 1}')\n",
    "        for i in range(len(X)):\n",
    "            # Calculate the output prediction using the dot product\n",
    "            prediction = np.dot(X[i], weights) + bias\n",
    "            # Apply the step function\n",
    "            if prediction * y[i] <= 0:  # Misclassification\n",
    "                # Update the weights and bias\n",
    "                weights += learning_rate * y[i] * X[i]\n",
    "                bias += learning_rate * y[i]\n",
    "                print(f'  Misclassified point {X[i]} - updating weights and bias')\n",
    "        \n",
    "    return weights, bias\n",
    "\n",
    "# Train the Perceptron\n",
    "weights, bias = perceptron(X, y)\n",
    "\n",
    "# Output the final weights and bias\n",
    "print(f'\\nFinal weights: {weights}')\n",
    "print(f'Final bias: {bias}')\n",
    "\n",
    "# Test the final classifier with a sample input\n",
    "def classify(X, weights, bias):\n",
    "    return np.sign(np.dot(X, weights) + bias)\n",
    "\n",
    "# Test the classifier on all points\n",
    "for i in range(len(X)):\n",
    "    pred = classify(X[i], weights, bias)\n",
    "    print(f'Point {X[i]} predicted as class {pred} (actual class {y[i]})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e15ee1-d205-4cf8-9e9e-8ac928cfe0f4",
   "metadata": {},
   "source": [
    "## 2B. Write a python program to find the number of linearly seperable problems out of total binary classification problems on\n",
    "## {P0(-1,-1,-1), P1(-1,-1,1), P2(-1,1,-1), P3(-1,1,1),P4(1,-1,-1), P5(1,-1,1), P6(1,1,-1), P7(1,1,1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c55bf3ab-1efc-4bc8-ad20-676c54ad5218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of linearly separable problems: 256 out of 256 possible labelings\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "# Define the dataset (X) - the 8 points in 3D\n",
    "X = np.array([[-1, -1, -1], [-1, -1, 1], [-1, 1, -1], [-1, 1, 1],\n",
    "              [1, -1, -1], [1, -1, 1], [1, 1, -1], [1, 1, 1]])\n",
    "\n",
    "# Perceptron Learning Algorithm\n",
    "def perceptron(X, y, learning_rate=0.1, epochs=10):\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    bias = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(len(X)):\n",
    "            prediction = np.dot(X[i], weights) + bias\n",
    "            if prediction * y[i] <= 0:  # Misclassification\n",
    "                weights += learning_rate * y[i] * X[i]\n",
    "                bias += learning_rate * y[i]\n",
    "    return weights, bias\n",
    "\n",
    "# Check if a given labeling is linearly separable\n",
    "def is_linearly_separable(X, y):\n",
    "    try:\n",
    "        weights, bias = perceptron(X, y)\n",
    "        return True  # If perceptron converges, it's linearly separable\n",
    "    except:\n",
    "        return False  # If the perceptron does not converge\n",
    "\n",
    "# Generate all possible binary labelings for the points\n",
    "all_labelings = list(itertools.product([-1, 1], repeat=8))\n",
    "\n",
    "# Count how many of the labelings are linearly separable\n",
    "linearly_separable_count = 0\n",
    "for labeling in all_labelings:\n",
    "    y = np.array(labeling)\n",
    "    if is_linearly_separable(X, y):\n",
    "        linearly_separable_count += 1\n",
    "\n",
    "print(f\"Number of linearly separable problems: {linearly_separable_count} out of {2**8} possible labelings\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa54ff-b9d1-454c-92b5-d729fdf00c7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
